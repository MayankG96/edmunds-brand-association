{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/rachana/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/rachana/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('edmunds.csv')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        `` bottom line think throw blanket cars terms ...\n",
      "1        legacy gt another one 'm looking forward . 'd ...\n",
      "2        `` g35 , tl & is300 worshipers gon na upset ne...\n",
      "3        review mag articles relate specifically gt , m...\n",
      "4        buy srt4 cheap , put $ 10k worth mods blow eve...\n",
      "                               ...                        \n",
      "17496    far know , , 3 series , infiniti g35 , acura t...\n",
      "17497    honestly , good reasons might choose tl g35 , ...\n",
      "17498    going include mazda stop , bring hyundai azera...\n",
      "17499    know , described lesson learnt hard way . boug...\n",
      "17500    `` . . .a base 328i . . .that miserable base e...\n",
      "Name: body, Length: 17501, dtype: object\n"
     ]
    }
   ],
   "source": [
    "stop = stopwords.words('english')\n",
    "def remove_stopwords(text):\n",
    "    words = nltk.word_tokenize(text)\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    return \" \".join(filtered_words)\n",
    "df['body']=df['body'].str.lower()\n",
    "\n",
    "df['body'] = df['body'].astype(str).apply(remove_stopwords)\n",
    "print(df['body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map the brand names to the car names\n",
    "mapping_df = pd.read_csv('car_models_and_brands.csv')\n",
    "model_to_brand = dict(zip(mapping_df['Model'], mapping_df['Brand']))\n",
    "def replace_model_with_brand(comment):\n",
    "    for model, brand in model_to_brand.items():\n",
    "        comment = comment.replace(model, brand)\n",
    "    return comment\n",
    "\n",
    "df['body'] = df['body'].str.lower().apply(replace_model_with_brand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "brands=mapping_df['Brand'].unique()\n",
    "values_to_remove = ['car', 'seat', 'problem','\"hyundai,\"','hyundai.','\"kia,\"','kia.','sedan']\n",
    "\n",
    "brands = [x for x in brands if x not in values_to_remove]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bmw': 5702, 'honda': 1374, 'infiniti': 1234, 'acura': 1699, 'subaru': 543, 'audi': 1531, 'ford': 512, 'dodge': 218, 'toyota': 1154, 'volkswagen': 543, 'mitsubishi': 75, 'nissan': 776, 'mercedes-benz': 780, 'volvo': 577, 'hyundai': 352, 'chevrolet': 364, 'saturn': 48, 'cadillac': 545, 'chrysler': 180, 'mazda': 284, 'pontiac': 185, 'lincoln': 430, 'kia': 68, 'suzuki': 48, 'buick': 172, 'mercury': 21}\n"
     ]
    }
   ],
   "source": [
    "brand_freq = {}\n",
    "\n",
    "# Iterate through the \"body\" column of the target DataFrame\n",
    "for _, row in df.iterrows():\n",
    "    body_text = row['body']\n",
    "    # Check for NaN values and skip them\n",
    "    if not isinstance(body_text, str) and np.isnan(body_text):\n",
    "        continue\n",
    "    \n",
    "    # Split the \"body\" text into words\n",
    "    words = body_text.split()\n",
    "\n",
    "    words = list(set(words))\n",
    "\n",
    "    # Count the frequency of brand names in the \"body\" text\n",
    "    for word in words:\n",
    "        if word in brands:\n",
    "            brand_freq[word] = brand_freq.get(word, 0) + 1\n",
    "\n",
    "# Now, brand_freq dictionary contains the frequency counts of brand names in the \"body\" column\n",
    "print(brand_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bmw: 5702\n",
      "acura: 1699\n",
      "audi: 1531\n",
      "honda: 1374\n",
      "infiniti: 1234\n",
      "toyota: 1154\n",
      "mercedes-benz: 780\n",
      "nissan: 776\n",
      "volvo: 577\n",
      "cadillac: 545\n"
     ]
    }
   ],
   "source": [
    "sorted_dict = sorted(brand_freq.items(), key=lambda item: item[1],reverse=True)\n",
    "top_10_brands=sorted_dict[:10]\n",
    "for brand, frequency in top_10_brands:\n",
    "    print(f'{brand}: {frequency}')\n",
    "top_10_list = [item[0] for item in top_10_brands]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_lift(brand1, brand2, co_mentions, individual_mentions, total_posts):\n",
    "    if brand1 == brand2:\n",
    "        return 0  # Lift ratio between the same brand is 0\n",
    "    # Calculate lift using the formula: lift(brand1, brand2) = (P(brand1 and brand2) / (P(brand1) * P(brand2))) * N\n",
    "    p_brand1_and_brand2 = co_mentions[brand1][brand2]\n",
    "    p_brand1 = individual_mentions[brand1]\n",
    "    p_brand2 = individual_mentions[brand2]\n",
    "    if p_brand1 == 0 or p_brand2 == 0:\n",
    "        return 0  \n",
    "    else:\n",
    "        return (p_brand1_and_brand2 / (p_brand1 * p_brand2)) * total_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize(list1, list2):\n",
    "    brand_mentions_per_post = {brand: set() for brand in list1 + list2}\n",
    "    co_mentions = {}\n",
    "    for brand1 in list1 + list2:\n",
    "        co_mentions[brand1] = {}\n",
    "        for brand2 in list1 + list2:\n",
    "            co_mentions[brand1][brand2] = 0\n",
    "    individual_mentions = {brand: 0 for brand in list1 + list2}\n",
    "    lift_ratios = {}\n",
    "    lift_already_calculated = set()\n",
    "    return co_mentions, brand_mentions_per_post, individual_mentions, lift_ratios, lift_already_calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "#co_mentions, brand_mentions_per_post, individual_mentions, lift_ratios, lift_already_calculated=initialize()\n",
    "\n",
    "def calculate_lift_ratios_between_lists(df, list1, list2,window):\n",
    "    co_mentions, brand_mentions_per_post, individual_mentions, lift_ratios, lift_already_calculated = initialize(list1,list2)\n",
    "    total_posts = len(df)\n",
    "    for _, row in df.iterrows():\n",
    "        body_text = row['body']\n",
    "        if not isinstance(body_text, str) and np.isnan(body_text):\n",
    "            continue\n",
    "\n",
    "        words = body_text.split()\n",
    "        words = [word.lower() for word in words]\n",
    "        mentioned_brands_in_post = set()\n",
    "        co_brands_in_post = set()\n",
    "\n",
    "        for i, word in enumerate(words):\n",
    "            if word in list1 or word in list2:\n",
    "                if word not in mentioned_brands_in_post:\n",
    "                    individual_mentions[word] += 1\n",
    "                    mentioned_brands_in_post.add(word)\n",
    "                    k=min(i + window, len(words))\n",
    "                    for j in range(i + 1, k):\n",
    "                        if words[j] in list1 or words[j] in list2:\n",
    "                            co_mentions[word][words[j]] += 1\n",
    "                            co_mentions[words[j]][word] += 1\n",
    "\n",
    "                elif word not in co_brands_in_post:\n",
    "                    for j in range(i + 1, k ):\n",
    "                        if words[j] in list1 or words[j] in list2:\n",
    "                            co_mentions[word][words[j]] += 1\n",
    "                            co_mentions[words[j]][word] += 1\n",
    "\n",
    "    lift_df = pd.DataFrame(index=list1, columns=list2)\n",
    "\n",
    "    for brand1 in list1:\n",
    "        for brand2 in list2:\n",
    "            pair = tuple(sorted([brand1, brand2]))\n",
    "            if pair not in lift_already_calculated:\n",
    "                lift_ratio = calculate_lift(brand1, brand2, co_mentions, individual_mentions, total_posts)\n",
    "                lift_df.loc[brand1, brand2] = lift_ratio\n",
    "                \n",
    "\n",
    "    return lift_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bmw</th>\n",
       "      <th>acura</th>\n",
       "      <th>audi</th>\n",
       "      <th>honda</th>\n",
       "      <th>infiniti</th>\n",
       "      <th>toyota</th>\n",
       "      <th>mercedes-benz</th>\n",
       "      <th>nissan</th>\n",
       "      <th>volvo</th>\n",
       "      <th>cadillac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bmw</th>\n",
       "      <td>0</td>\n",
       "      <td>0.502212</td>\n",
       "      <td>0.819943</td>\n",
       "      <td>0.218915</td>\n",
       "      <td>0.753639</td>\n",
       "      <td>0.25533</td>\n",
       "      <td>0.908977</td>\n",
       "      <td>0.162165</td>\n",
       "      <td>0.303204</td>\n",
       "      <td>0.799701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acura</th>\n",
       "      <td>0.502212</td>\n",
       "      <td>0</td>\n",
       "      <td>1.177423</td>\n",
       "      <td>1.004587</td>\n",
       "      <td>2.028433</td>\n",
       "      <td>0.249932</td>\n",
       "      <td>0.699924</td>\n",
       "      <td>0.438048</td>\n",
       "      <td>0.642682</td>\n",
       "      <td>1.020626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>audi</th>\n",
       "      <td>0.819943</td>\n",
       "      <td>1.177423</td>\n",
       "      <td>0</td>\n",
       "      <td>0.257907</td>\n",
       "      <td>1.250565</td>\n",
       "      <td>0.257546</td>\n",
       "      <td>1.743974</td>\n",
       "      <td>0.147308</td>\n",
       "      <td>2.278294</td>\n",
       "      <td>1.803805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>honda</th>\n",
       "      <td>0.218915</td>\n",
       "      <td>1.004587</td>\n",
       "      <td>0.257907</td>\n",
       "      <td>0</td>\n",
       "      <td>0.330302</td>\n",
       "      <td>3.156722</td>\n",
       "      <td>0.342926</td>\n",
       "      <td>2.281546</td>\n",
       "      <td>0.5298</td>\n",
       "      <td>0.233711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>infiniti</th>\n",
       "      <td>0.753639</td>\n",
       "      <td>2.028433</td>\n",
       "      <td>1.250565</td>\n",
       "      <td>0.330302</td>\n",
       "      <td>0</td>\n",
       "      <td>0.245794</td>\n",
       "      <td>0.763664</td>\n",
       "      <td>0.584839</td>\n",
       "      <td>0.44243</td>\n",
       "      <td>1.327154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toyota</th>\n",
       "      <td>0.25533</td>\n",
       "      <td>0.249932</td>\n",
       "      <td>0.257546</td>\n",
       "      <td>3.156722</td>\n",
       "      <td>0.245794</td>\n",
       "      <td>0</td>\n",
       "      <td>0.272201</td>\n",
       "      <td>2.5797</td>\n",
       "      <td>0.262834</td>\n",
       "      <td>0.111307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mercedes-benz</th>\n",
       "      <td>0.908977</td>\n",
       "      <td>0.699924</td>\n",
       "      <td>1.743974</td>\n",
       "      <td>0.342926</td>\n",
       "      <td>0.763664</td>\n",
       "      <td>0.272201</td>\n",
       "      <td>0</td>\n",
       "      <td>0.173483</td>\n",
       "      <td>2.838673</td>\n",
       "      <td>1.934949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nissan</th>\n",
       "      <td>0.162165</td>\n",
       "      <td>0.438048</td>\n",
       "      <td>0.147308</td>\n",
       "      <td>2.281546</td>\n",
       "      <td>0.584839</td>\n",
       "      <td>2.5797</td>\n",
       "      <td>0.173483</td>\n",
       "      <td>0</td>\n",
       "      <td>0.312691</td>\n",
       "      <td>0.331051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>volvo</th>\n",
       "      <td>0.303204</td>\n",
       "      <td>0.642682</td>\n",
       "      <td>2.278294</td>\n",
       "      <td>0.5298</td>\n",
       "      <td>0.44243</td>\n",
       "      <td>0.262834</td>\n",
       "      <td>2.838673</td>\n",
       "      <td>0.312691</td>\n",
       "      <td>0</td>\n",
       "      <td>0.667839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cadillac</th>\n",
       "      <td>0.799701</td>\n",
       "      <td>1.020626</td>\n",
       "      <td>1.803805</td>\n",
       "      <td>0.233711</td>\n",
       "      <td>1.327154</td>\n",
       "      <td>0.111307</td>\n",
       "      <td>1.934949</td>\n",
       "      <td>0.331051</td>\n",
       "      <td>0.667839</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    bmw     acura      audi     honda  infiniti    toyota  \\\n",
       "bmw                   0  0.502212  0.819943  0.218915  0.753639   0.25533   \n",
       "acura          0.502212         0  1.177423  1.004587  2.028433  0.249932   \n",
       "audi           0.819943  1.177423         0  0.257907  1.250565  0.257546   \n",
       "honda          0.218915  1.004587  0.257907         0  0.330302  3.156722   \n",
       "infiniti       0.753639  2.028433  1.250565  0.330302         0  0.245794   \n",
       "toyota          0.25533  0.249932  0.257546  3.156722  0.245794         0   \n",
       "mercedes-benz  0.908977  0.699924  1.743974  0.342926  0.763664  0.272201   \n",
       "nissan         0.162165  0.438048  0.147308  2.281546  0.584839    2.5797   \n",
       "volvo          0.303204  0.642682  2.278294    0.5298   0.44243  0.262834   \n",
       "cadillac       0.799701  1.020626  1.803805  0.233711  1.327154  0.111307   \n",
       "\n",
       "              mercedes-benz    nissan     volvo  cadillac  \n",
       "bmw                0.908977  0.162165  0.303204  0.799701  \n",
       "acura              0.699924  0.438048  0.642682  1.020626  \n",
       "audi               1.743974  0.147308  2.278294  1.803805  \n",
       "honda              0.342926  2.281546    0.5298  0.233711  \n",
       "infiniti           0.763664  0.584839   0.44243  1.327154  \n",
       "toyota             0.272201    2.5797  0.262834  0.111307  \n",
       "mercedes-benz             0  0.173483  2.838673  1.934949  \n",
       "nissan             0.173483         0  0.312691  0.331051  \n",
       "volvo              2.838673  0.312691         0  0.667839  \n",
       "cadillac           1.934949  0.331051  0.667839         0  "
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_lift_ratios=calculate_lift_ratios_between_lists(df,top_10_list, top_10_list, 7)\n",
    "sorted_lift_ratios "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[148], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39m# Extract the unique brand names\u001b[39;00m\n\u001b[1;32m      6\u001b[0m brands \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n\u001b[0;32m----> 7\u001b[0m \u001b[39mfor\u001b[39;00m lift_item, _ \u001b[39min\u001b[39;00m sorted_lift_ratios:\n\u001b[1;32m      8\u001b[0m     brands\u001b[39m.\u001b[39mupdate(lift_item)\n\u001b[1;32m      9\u001b[0m brands \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(brands)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.manifold import MDS\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract the unique brand names\n",
    "brands = set()\n",
    "for lift_item, _ in sorted_lift_ratios:\n",
    "    brands.update(lift_item)\n",
    "brands = list(brands)\n",
    "\n",
    "# Create an empty dissimilarity matrix\n",
    "n = len(brands)\n",
    "dissimilarity_matrix = np.zeros((n, n))\n",
    "\n",
    "# Fill the dissimilarity matrix with lift values\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        if i != j:\n",
    "            brand_pair = (brands[i], brands[j])\n",
    "            # Find the lift value for the brand pair\n",
    "            for lift_item, lift_value in sorted_lift_ratios:\n",
    "                if brand_pair == lift_item or brand_pair == lift_item[::-1]:\n",
    "                    dissimilarity_matrix[i, j] = 1 / lift_value  # You may need to adjust this scaling\n",
    "                    break\n",
    "\n",
    "# Initialize the MDS model\n",
    "mds = MDS(n_components=2, dissimilarity=\"precomputed\")\n",
    "\n",
    "# Fit the data and perform MDS mapping\n",
    "mds_result = mds.fit_transform(dissimilarity_matrix)\n",
    "\n",
    "# Plot the MDS results with labels\n",
    "plt.figure(figsize=(13, 9))\n",
    "plt.scatter(mds_result[:, 0], mds_result[:, 1])\n",
    "for i, brand in enumerate(brands):\n",
    "    plt.annotate(brand, (mds_result[i, 0], mds_result[i, 1]))\n",
    "plt.title(\"MDS Mapping based on Lift Values\")\n",
    "plt.xlabel(\"Dimension 1\")\n",
    "plt.ylabel(\"Dimension 2\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the analyses you provided from Tasks C and D, you can offer the following insights and recommendations to your client, JD Power and Associates:\n",
    "\n",
    "**Insights from Task C (Lift Analysis):**\n",
    "\n",
    "1. **Brand Associations**: The lift values indicate the strength of associations between different car brands mentioned in social media conversations. For instance, Mercedes-Benz and Volvo have a high lift value of 4.63, suggesting that these brands are frequently mentioned together in discussions. Honda and Toyota also have a strong association with a lift value of 4.16. This information can help your client understand which brands are often discussed in relation to each other and identify potential competitors or collaboration opportunities.\n",
    "\n",
    "2. **Distinctiveness**: Lower lift values suggest less strong associations between brands. For example, Honda and Infiniti have a lift value of 1.66, indicating that they are mentioned together less frequently. Understanding these distinctions can help your client identify which brands have a more unique or separate market presence.\n",
    "\n",
    "3. **Potential Partnerships**: Brands with moderate lift values may consider exploring partnerships or collaborations. For example, Audi and Cadillac have a lift value of 2.18, indicating some association. Your client could advise these brands to explore potential co-marketing or co-branding opportunities to leverage this association.\n",
    "\n",
    "**Insights from Task D (MDS Map Analysis):**\n",
    "\n",
    "1. **Brand Clustering**: The MDS map shows how different car brands are positioned in terms of similarity in social media conversations. The cluster of BMW, Audi, Mercedes, and Cadillac suggests that these brands are closely related in the context of the entry-level luxury car market. They may share similar customer perceptions, characteristics, or competition.\n",
    "\n",
    "2. **Distinct Clusters**: The presence of distinct clusters on the MDS map indicates that some brands are more closely related to each other than to others. For example, Nissan, Honda, and Toyota form a separate cluster, indicating that they may be perceived differently or have different customer bases compared to the luxury brands in the first cluster.\n",
    "\n",
    "**Recommendations:**\n",
    "\n",
    "1. **Competitive Analysis**: Based on the brand associations identified in Task C, your client can perform a more in-depth competitive analysis of specific brand pairs with high lift values. This analysis can include examining consumer sentiment, product features, and market positioning to gain a deeper understanding of the relationships between these brands.\n",
    "\n",
    "2. **Market Segmentation**: The MDS map from Task D can inform market segmentation strategies. Your client can consider targeting specific customer segments based on their preferences for certain brand clusters. For example, the cluster of luxury brands (BMW, Audi, Mercedes, Cadillac) may appeal to a different audience than the cluster of Nissan, Honda, and Toyota.\n",
    "\n",
    "3. **Partnership Opportunities**: Brands with moderate lift values, such as Audi and Cadillac, may explore partnership opportunities to cross-promote or collaborate on marketing campaigns. This can help them leverage the existing associations between their brands to reach a broader audience.\n",
    "\n",
    "4. **Consumer Perception Analysis**: Use sentiment analysis and social media monitoring tools to gain insights into how consumers perceive and discuss these brands. Are there common themes or pain points that emerge in discussions about certain brands? This information can guide brand improvement strategies.\n",
    "\n",
    "In summary, your analysis provides valuable insights into brand associations and positioning in the entry-level luxury car market. These insights can inform marketing, partnership, and segmentation strategies to help your client make data-driven decisions and stay competitive in the industry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       braking - sorry 70 0 braking 189 retoyotad c &...\n",
      "1       new 2004 honda drove driveway last night . goo...\n",
      "2       love numbers , compare performance price numbe...\n",
      "3       kd , people buy tl honda , reason bought 330 3...\n",
      "4       ppontiac8477 ... prove point . luxury primary ...\n",
      "                              ...                        \n",
      "4995    `` meaningless '' guess 's meaningless actuall...\n",
      "4996    guess everyone hung whole msrp value thing . g...\n",
      "4997    please stop yelling ! consider used chevrolet ...\n",
      "4998    response exepected ... discounting areas bmw e...\n",
      "4999    `` please mountain , curvy , wavy road nonsens...\n",
      "Name: body, Length: 5000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df['body'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>body</th>\n",
       "      <th>dates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chrisboth</td>\n",
       "      <td>`` bottom line think throw blanket car terms p...</td>\n",
       "      <td>January 27, 2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>qbrozen</td>\n",
       "      <td>subaru gt another one 'm looking forward . 'd ...</td>\n",
       "      <td>January 8, 2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chrisboth</td>\n",
       "      <td>`` pontiac5 , tl &amp; is300 worshipers gon na ups...</td>\n",
       "      <td>January 8, 2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>buddhabman</td>\n",
       "      <td>review mag articles relate specifically gt , m...</td>\n",
       "      <td>January 8, 2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kdshapiro</td>\n",
       "      <td>buy srt4 cheap , put $ 10k worth mods blow eve...</td>\n",
       "      <td>January 8, 2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17496</th>\n",
       "      <td>sjaieve</td>\n",
       "      <td>far know , , 3 series , infiniti pontiac5 , ac...</td>\n",
       "      <td>March 11, 2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17497</th>\n",
       "      <td>riorebel</td>\n",
       "      <td>honestly , good reasons might choose tl pontia...</td>\n",
       "      <td>March 11, 2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17498</th>\n",
       "      <td>plekto</td>\n",
       "      <td>going include mazda stop , bring hyundai hyund...</td>\n",
       "      <td>March 11, 2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17499</th>\n",
       "      <td>sjaieve</td>\n",
       "      <td>know , described lesson learnt hard way . boug...</td>\n",
       "      <td>March 11, 2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17500</th>\n",
       "      <td>cdnpinhead</td>\n",
       "      <td>`` . . .a base bmw with. . .that miserable bas...</td>\n",
       "      <td>March 11, 2008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17501 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           author                                               body  \\\n",
       "0       chrisboth  `` bottom line think throw blanket car terms p...   \n",
       "1         qbrozen  subaru gt another one 'm looking forward . 'd ...   \n",
       "2       chrisboth  `` pontiac5 , tl & is300 worshipers gon na ups...   \n",
       "3      buddhabman  review mag articles relate specifically gt , m...   \n",
       "4       kdshapiro  buy srt4 cheap , put $ 10k worth mods blow eve...   \n",
       "...           ...                                                ...   \n",
       "17496     sjaieve  far know , , 3 series , infiniti pontiac5 , ac...   \n",
       "17497    riorebel  honestly , good reasons might choose tl pontia...   \n",
       "17498      plekto  going include mazda stop , bring hyundai hyund...   \n",
       "17499     sjaieve  know , described lesson learnt hard way . boug...   \n",
       "17500  cdnpinhead  `` . . .a base bmw with. . .that miserable bas...   \n",
       "\n",
       "                  dates  \n",
       "0      January 27, 2004  \n",
       "1       January 8, 2004  \n",
       "2       January 8, 2004  \n",
       "3       January 8, 2004  \n",
       "4       January 8, 2004  \n",
       "...                 ...  \n",
       "17496    March 11, 2008  \n",
       "17497    March 11, 2008  \n",
       "17498    March 11, 2008  \n",
       "17499    March 11, 2008  \n",
       "17500    March 11, 2008  \n",
       "\n",
       "[17501 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new=pd.DataFrame()\n",
    "from nltk import word_tokenize, FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string \n",
    "def remove_punctuation(text):\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    text = text.translate(translator)\n",
    "    return text\n",
    "\n",
    "# Remove punctuations from the 'body' column\n",
    "df['body'] = df['body'].apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 100 Most Frequently Mentioned Attributes/Features:\n",
      "car\n",
      "s\n",
      "nt\n",
      "bmw\n",
      "tl\n",
      "like\n",
      "would\n",
      "one\n",
      "pontiac5\n",
      "get\n",
      "think\n",
      "drive\n",
      "3\n",
      "better\n",
      "sedan\n",
      "new\n",
      "m\n",
      "much\n",
      "performance\n",
      "acura\n",
      "people\n",
      "audi\n",
      "even\n",
      "good\n",
      "driving\n",
      "really\n",
      "know\n",
      "best\n",
      "want\n",
      "luxury\n",
      "well\n",
      "rwd\n",
      "honda\n",
      "also\n",
      "still\n",
      "330i\n",
      "engine\n",
      "series\n",
      "way\n",
      "say\n",
      "infiniti\n",
      "could\n",
      "time\n",
      "ve\n",
      "price\n",
      "make\n",
      "see\n",
      "fwd\n",
      "lexus\n",
      "d\n",
      "handling\n",
      "buy\n",
      "great\n",
      "go\n",
      "awd\n",
      "re\n",
      "hp\n",
      "interior\n",
      "ll\n",
      "power\n",
      "g\n",
      "many\n",
      "nissan\n",
      "years\n",
      "back\n",
      "going\n",
      "tires\n",
      "manual\n",
      "less\n",
      "test\n",
      "look\n",
      "toyota\n",
      "got\n",
      "right\n",
      "ca\n",
      "take\n",
      "may\n",
      "feel\n",
      "sport\n",
      "never\n",
      "two\n",
      "toyotad\n",
      "subaru\n",
      "sales\n",
      "point\n",
      "need\n",
      "2\n",
      "seat\n",
      "sure\n",
      "different\n",
      "cts\n",
      "thing\n",
      "lot\n",
      "year\n",
      "maybe\n",
      "road\n",
      "torque\n",
      "5\n",
      "little\n",
      "around\n"
     ]
    }
   ],
   "source": [
    "df_new['tokenized_text'] = df['body'].apply(word_tokenize)\n",
    "\n",
    "# Flatten the list of tokenized words\n",
    "all_words = [word for sublist in df_new['tokenized_text'] for word in sublist]\n",
    "\n",
    "# Calculate word frequencies\n",
    "freq_dist = FreqDist(all_words)\n",
    "\n",
    "# Get the most common words (you can adjust the number)\n",
    "num_most_common = 100\n",
    "most_common_attributes = freq_dist.most_common(num_most_common)\n",
    "\n",
    "# Extract the attribute names (words) from the most common words\n",
    "top_attributes = [word for word, frequency in most_common_attributes]\n",
    "\n",
    "print(\"Top\", num_most_common, \"Most Frequently Mentioned Attributes/Features:\")\n",
    "for attribute in top_attributes:\n",
    "    print(attribute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>performance</th>\n",
       "      <th>drive</th>\n",
       "      <th>luxury</th>\n",
       "      <th>driving</th>\n",
       "      <th>price</th>\n",
       "      <th>interior</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bmw</th>\n",
       "      <td>1.907702</td>\n",
       "      <td>1.283274</td>\n",
       "      <td>1.374045</td>\n",
       "      <td>1.545154</td>\n",
       "      <td>1.950953</td>\n",
       "      <td>1.374198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acura</th>\n",
       "      <td>1.245045</td>\n",
       "      <td>1.363075</td>\n",
       "      <td>1.99444</td>\n",
       "      <td>0.852515</td>\n",
       "      <td>1.267884</td>\n",
       "      <td>1.334417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>audi</th>\n",
       "      <td>1.464463</td>\n",
       "      <td>1.556993</td>\n",
       "      <td>2.014994</td>\n",
       "      <td>1.452237</td>\n",
       "      <td>1.23901</td>\n",
       "      <td>3.377368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>honda</th>\n",
       "      <td>1.308899</td>\n",
       "      <td>1.213334</td>\n",
       "      <td>2.430558</td>\n",
       "      <td>1.920325</td>\n",
       "      <td>1.567783</td>\n",
       "      <td>1.466715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>infiniti</th>\n",
       "      <td>0.995139</td>\n",
       "      <td>1.026997</td>\n",
       "      <td>1.444423</td>\n",
       "      <td>0.695286</td>\n",
       "      <td>1.337464</td>\n",
       "      <td>1.772792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         performance     drive    luxury   driving     price  interior\n",
       "bmw         1.907702  1.283274  1.374045  1.545154  1.950953  1.374198\n",
       "acura       1.245045  1.363075   1.99444  0.852515  1.267884  1.334417\n",
       "audi        1.464463  1.556993  2.014994  1.452237   1.23901  3.377368\n",
       "honda       1.308899  1.213334  2.430558  1.920325  1.567783  1.466715\n",
       "infiniti    0.995139  1.026997  1.444423  0.695286  1.337464  1.772792"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributes=[\"performance\",\"drive\",\"luxury\",\"driving\",\"price\",\"interior\"]\n",
    "top_10_lift=calculate_lift_ratios_between_lists(df,top_10_list[:5], attributes,30)\n",
    "top_10_lift\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now for our top 10 brands, lets find the lift of those brands with these buying or owning related terms\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
